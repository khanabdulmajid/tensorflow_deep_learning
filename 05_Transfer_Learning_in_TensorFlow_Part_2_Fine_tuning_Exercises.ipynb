{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoKXXoYyZEjmEgcBV29KKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanabdulmajid/tensorflow_deep_learning/blob/main/05_Transfer_Learning_in_TensorFlow_Part_2_Fine_tuning_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ›  05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises\n",
        "1. Use feature-extraction to train a transfer learning model on 10% of the Food Vision data for 10 epochs using `tf.keras.applications.EfficientNetB0` as the base model. Use the ModelCheckpoint callback to save the weights to file.\n",
        "2. Fine-tune the last 20 layers of the base model you trained in 2 for another 10 epochs. How did it go?\n",
        "3. Fine-tune the last 30 layers of the base model you trained in 2 for another 10 epochs. How did it go?\n",
        "4. Write a function to visualize an image from any dataset (train or test file) and any class (e.g. \"steak\", \"pizza\"... etc), visualize it and make a prediction on it using a trained model.\n",
        "ðŸ“–\n",
        "# 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum\n",
        "* Read the documentation on data augmentation in TensorFlow.\n",
        "* Read the ULMFit paper (technical) for an introduction to the concept of freezing and unfreezing different layers.\n",
        "* Read up on learning rate scheduling (there's a TensorFlow callback for this), how could this influence our model training?\n",
        "> * If you're training for longer, you probably want to reduce the learning rate as you go... the closer you get to the bottom of the hill, the smaller steps you want to take. Imagine it like finding a coin at the bottom of your couch. In the beginning your arm movements are going to be large and the closer you get, the smaller your movements become.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vtdUA1swqe1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bek6UBw7qUWO",
        "outputId": "b583f559-f25f-4ef1-80ea-db2735296e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-28 11:01:07--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-28 11:01:07 (91.4 MB/s) - â€˜helper_functions.pyâ€™ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-SALudotUQP",
        "outputId": "cabe678e-2589-477b-f7f9-8d01858dc83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-28 11:01:12--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.163.128, 142.251.167.128, 172.253.115.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.163.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zipâ€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   278MB/s    in 0.6s    \n",
            "\n",
            "2023-08-28 11:01:12 (278 MB/s) - â€˜10_food_classes_10_percent.zipâ€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "chhLrftStbCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Use feature-extraction to train a transfer learning model on 10% of the Food Vision data for 10 epochs using `tf.keras.applications.EfficientNetB0` as the base model. Use the ModelCheckpoint callback to save the weights to file."
      ],
      "metadata": {
        "id": "-cSaCq96t8Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"food_vision_checkpoint/\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only=True)\n",
        "\n",
        "base_model= tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mJj9d6wtyGc",
        "outputId": "1bc234d0-289b-406c-90db-438a5dcb3d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,layers in enumerate(base_model.layers):\n",
        "  print(i,layers.name)"
      ],
      "metadata": {
        "id": "I21g9MFFuSH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ouCRvYn6lgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/10_food_classes_10_percent/train\"\n",
        "test_dir = \"/content/10_food_classes_10_percent/test\""
      ],
      "metadata": {
        "id": "6rpP30NpuTmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE=(224,224)\n",
        "train_data_10_percent= tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=train_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    image_size=IMG_SIZE\n",
        ")\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=test_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    image_size=IMG_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdD5Fh00wGPN",
        "outputId": "c158c2a5-4e71-4d65-88b5-8e2a4f40c872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs= tf.keras.layers.Input(shape=(224,224,3),name=\"inputLayer\")\n",
        "data_augmentation=tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "  tf.keras.layers.RandomZoom(0.2),\n",
        "  tf.keras.layers.RandomHeight(0.2),\n",
        "  tf.keras.layers.RandomWidth(0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation_layer\"\n",
        "    )\n",
        "\n",
        "x = data_augmentation (inputs)\n",
        "\n",
        "x=base_model(x,training=False)\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"GlobalAveragePooling\")(x)\n",
        "output = tf.keras.layers.Dense(10,activation=\"softmax\",name=\"output_Layer\")(x)\n",
        "model_0 = tf.keras.Model(inputs,output)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y1K_ZUVD4TpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"]\n",
        "                )\n",
        "\n",
        "history_10_percent=model_0.fit(\n",
        "    train_data_10_percent,\n",
        "    epochs=10,\n",
        "    validation_data=test_data,\n",
        "    validation_steps=int(0.25*len(test_data)),\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mybtUP6Y7Cbl",
        "outputId": "bc84369f-716c-47db-d7cc-2d69e7a3530b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 151s 6s/step - loss: 1.9817 - accuracy: 0.3400 - val_loss: 1.4262 - val_accuracy: 0.6513\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 142s 6s/step - loss: 1.3038 - accuracy: 0.6920 - val_loss: 0.9576 - val_accuracy: 0.7928\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 143s 6s/step - loss: 0.9897 - accuracy: 0.7600 - val_loss: 0.7609 - val_accuracy: 0.8273\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 144s 6s/step - loss: 0.8325 - accuracy: 0.7893 - val_loss: 0.6614 - val_accuracy: 0.8470\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 146s 6s/step - loss: 0.7322 - accuracy: 0.8147 - val_loss: 0.5973 - val_accuracy: 0.8734\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 150s 6s/step - loss: 0.6595 - accuracy: 0.8480 - val_loss: 0.5624 - val_accuracy: 0.8618\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 131s 6s/step - loss: 0.5808 - accuracy: 0.8707 - val_loss: 0.5521 - val_accuracy: 0.8520\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.5520 - accuracy: 0.8560 - val_loss: 0.5019 - val_accuracy: 0.8783\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 147s 6s/step - loss: 0.5140 - accuracy: 0.8840 - val_loss: 0.4800 - val_accuracy: 0.8783\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 148s 6s/step - loss: 0.4850 - accuracy: 0.8893 - val_loss: 0.4629 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dPvZeMvr9xyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Fine-tune the last 20 layers of the base model you trained in 2 for another 10 epochs. How did it go?"
      ],
      "metadata": {
        "id": "nFV5cGeuEWTb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0bNrXS7EYSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.layers[2].trainable=True\n",
        "for layer in model_0.layers[2].layers[:-20]:\n",
        "  layer.trainable=False\n"
      ],
      "metadata": {
        "id": "XOUe7UD7FA11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_0.layers[2].layers:\n",
        "  print(layer.name, layer.trainable)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2LYr8TULNxl",
        "outputId": "0ceea2e6-8398-4689-f12c-40c461b156ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 False\n",
            "rescaling False\n",
            "normalization False\n",
            "rescaling_1 False\n",
            "stem_conv_pad False\n",
            "stem_conv False\n",
            "stem_bn False\n",
            "stem_activation False\n",
            "block1a_dwconv False\n",
            "block1a_bn False\n",
            "block1a_activation False\n",
            "block1a_se_squeeze False\n",
            "block1a_se_reshape False\n",
            "block1a_se_reduce False\n",
            "block1a_se_expand False\n",
            "block1a_se_excite False\n",
            "block1a_project_conv False\n",
            "block1a_project_bn False\n",
            "block2a_expand_conv False\n",
            "block2a_expand_bn False\n",
            "block2a_expand_activation False\n",
            "block2a_dwconv_pad False\n",
            "block2a_dwconv False\n",
            "block2a_bn False\n",
            "block2a_activation False\n",
            "block2a_se_squeeze False\n",
            "block2a_se_reshape False\n",
            "block2a_se_reduce False\n",
            "block2a_se_expand False\n",
            "block2a_se_excite False\n",
            "block2a_project_conv False\n",
            "block2a_project_bn False\n",
            "block2b_expand_conv False\n",
            "block2b_expand_bn False\n",
            "block2b_expand_activation False\n",
            "block2b_dwconv False\n",
            "block2b_bn False\n",
            "block2b_activation False\n",
            "block2b_se_squeeze False\n",
            "block2b_se_reshape False\n",
            "block2b_se_reduce False\n",
            "block2b_se_expand False\n",
            "block2b_se_excite False\n",
            "block2b_project_conv False\n",
            "block2b_project_bn False\n",
            "block2b_drop False\n",
            "block2b_add False\n",
            "block3a_expand_conv False\n",
            "block3a_expand_bn False\n",
            "block3a_expand_activation False\n",
            "block3a_dwconv_pad False\n",
            "block3a_dwconv False\n",
            "block3a_bn False\n",
            "block3a_activation False\n",
            "block3a_se_squeeze False\n",
            "block3a_se_reshape False\n",
            "block3a_se_reduce False\n",
            "block3a_se_expand False\n",
            "block3a_se_excite False\n",
            "block3a_project_conv False\n",
            "block3a_project_bn False\n",
            "block3b_expand_conv False\n",
            "block3b_expand_bn False\n",
            "block3b_expand_activation False\n",
            "block3b_dwconv False\n",
            "block3b_bn False\n",
            "block3b_activation False\n",
            "block3b_se_squeeze False\n",
            "block3b_se_reshape False\n",
            "block3b_se_reduce False\n",
            "block3b_se_expand False\n",
            "block3b_se_excite False\n",
            "block3b_project_conv False\n",
            "block3b_project_bn False\n",
            "block3b_drop False\n",
            "block3b_add False\n",
            "block4a_expand_conv False\n",
            "block4a_expand_bn False\n",
            "block4a_expand_activation False\n",
            "block4a_dwconv_pad False\n",
            "block4a_dwconv False\n",
            "block4a_bn False\n",
            "block4a_activation False\n",
            "block4a_se_squeeze False\n",
            "block4a_se_reshape False\n",
            "block4a_se_reduce False\n",
            "block4a_se_expand False\n",
            "block4a_se_excite False\n",
            "block4a_project_conv False\n",
            "block4a_project_bn False\n",
            "block4b_expand_conv False\n",
            "block4b_expand_bn False\n",
            "block4b_expand_activation False\n",
            "block4b_dwconv False\n",
            "block4b_bn False\n",
            "block4b_activation False\n",
            "block4b_se_squeeze False\n",
            "block4b_se_reshape False\n",
            "block4b_se_reduce False\n",
            "block4b_se_expand False\n",
            "block4b_se_excite False\n",
            "block4b_project_conv False\n",
            "block4b_project_bn False\n",
            "block4b_drop False\n",
            "block4b_add False\n",
            "block4c_expand_conv False\n",
            "block4c_expand_bn False\n",
            "block4c_expand_activation False\n",
            "block4c_dwconv False\n",
            "block4c_bn False\n",
            "block4c_activation False\n",
            "block4c_se_squeeze False\n",
            "block4c_se_reshape False\n",
            "block4c_se_reduce False\n",
            "block4c_se_expand False\n",
            "block4c_se_excite False\n",
            "block4c_project_conv False\n",
            "block4c_project_bn False\n",
            "block4c_drop False\n",
            "block4c_add False\n",
            "block5a_expand_conv False\n",
            "block5a_expand_bn False\n",
            "block5a_expand_activation False\n",
            "block5a_dwconv False\n",
            "block5a_bn False\n",
            "block5a_activation False\n",
            "block5a_se_squeeze False\n",
            "block5a_se_reshape False\n",
            "block5a_se_reduce False\n",
            "block5a_se_expand False\n",
            "block5a_se_excite False\n",
            "block5a_project_conv False\n",
            "block5a_project_bn False\n",
            "block5b_expand_conv False\n",
            "block5b_expand_bn False\n",
            "block5b_expand_activation False\n",
            "block5b_dwconv False\n",
            "block5b_bn False\n",
            "block5b_activation False\n",
            "block5b_se_squeeze False\n",
            "block5b_se_reshape False\n",
            "block5b_se_reduce False\n",
            "block5b_se_expand False\n",
            "block5b_se_excite False\n",
            "block5b_project_conv False\n",
            "block5b_project_bn False\n",
            "block5b_drop False\n",
            "block5b_add False\n",
            "block5c_expand_conv False\n",
            "block5c_expand_bn False\n",
            "block5c_expand_activation False\n",
            "block5c_dwconv False\n",
            "block5c_bn False\n",
            "block5c_activation False\n",
            "block5c_se_squeeze False\n",
            "block5c_se_reshape False\n",
            "block5c_se_reduce False\n",
            "block5c_se_expand False\n",
            "block5c_se_excite False\n",
            "block5c_project_conv False\n",
            "block5c_project_bn False\n",
            "block5c_drop False\n",
            "block5c_add False\n",
            "block6a_expand_conv False\n",
            "block6a_expand_bn False\n",
            "block6a_expand_activation False\n",
            "block6a_dwconv_pad False\n",
            "block6a_dwconv False\n",
            "block6a_bn False\n",
            "block6a_activation False\n",
            "block6a_se_squeeze False\n",
            "block6a_se_reshape False\n",
            "block6a_se_reduce False\n",
            "block6a_se_expand False\n",
            "block6a_se_excite False\n",
            "block6a_project_conv False\n",
            "block6a_project_bn False\n",
            "block6b_expand_conv False\n",
            "block6b_expand_bn False\n",
            "block6b_expand_activation False\n",
            "block6b_dwconv False\n",
            "block6b_bn False\n",
            "block6b_activation False\n",
            "block6b_se_squeeze False\n",
            "block6b_se_reshape False\n",
            "block6b_se_reduce False\n",
            "block6b_se_expand False\n",
            "block6b_se_excite False\n",
            "block6b_project_conv False\n",
            "block6b_project_bn False\n",
            "block6b_drop False\n",
            "block6b_add False\n",
            "block6c_expand_conv False\n",
            "block6c_expand_bn False\n",
            "block6c_expand_activation False\n",
            "block6c_dwconv False\n",
            "block6c_bn False\n",
            "block6c_activation False\n",
            "block6c_se_squeeze False\n",
            "block6c_se_reshape False\n",
            "block6c_se_reduce False\n",
            "block6c_se_expand False\n",
            "block6c_se_excite False\n",
            "block6c_project_conv False\n",
            "block6c_project_bn False\n",
            "block6c_drop False\n",
            "block6c_add False\n",
            "block6d_expand_conv False\n",
            "block6d_expand_bn False\n",
            "block6d_expand_activation False\n",
            "block6d_dwconv False\n",
            "block6d_bn False\n",
            "block6d_activation False\n",
            "block6d_se_squeeze False\n",
            "block6d_se_reshape False\n",
            "block6d_se_reduce False\n",
            "block6d_se_expand False\n",
            "block6d_se_excite False\n",
            "block6d_project_conv True\n",
            "block6d_project_bn True\n",
            "block6d_drop True\n",
            "block6d_add True\n",
            "block7a_expand_conv True\n",
            "block7a_expand_bn True\n",
            "block7a_expand_activation True\n",
            "block7a_dwconv True\n",
            "block7a_bn True\n",
            "block7a_activation True\n",
            "block7a_se_squeeze True\n",
            "block7a_se_reshape True\n",
            "block7a_se_reduce True\n",
            "block7a_se_expand True\n",
            "block7a_se_excite True\n",
            "block7a_project_conv True\n",
            "block7a_project_bn True\n",
            "top_conv True\n",
            "top_bn True\n",
            "top_activation True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_10_percent.epoch[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_hnbOx2nIzn",
        "outputId": "4292c7ee-bd96-4fcf-8d33-89dfc580ebc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_epochs=10\n",
        "fine_tuning_epochs =initial_epochs+10\n",
        "model_0.layers[2].trainable=True\n",
        "for layer in model_0.layers[2].layers[:-20]:\n",
        "  layer.trainable=False\n",
        "\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"]\n",
        "                )\n",
        "\n",
        "history_10_percent_10_trainable_layers=model_0.fit(\n",
        "    train_data_10_percent,\n",
        "    epochs=fine_tuning_epochs,\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    callbacks=[checkpoint_callback],\n",
        "    initial_epoch=history_10_percent.epoch[-1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0tBgJjhF4Up",
        "outputId": "9757a6d1-b4e8-45fe-8577-bc864f8f16de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20\n",
            "24/24 [==============================] - 282s 12s/step - loss: 0.6593 - accuracy: 0.7947 - val_loss: 0.4735 - val_accuracy: 0.8540\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 268s 12s/step - loss: 0.2787 - accuracy: 0.9147 - val_loss: 0.6688 - val_accuracy: 0.8168\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 279s 12s/step - loss: 0.1887 - accuracy: 0.9387 - val_loss: 0.4183 - val_accuracy: 0.8792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Fine-tune the last 30 layers of the base model you trained in 2 for another 10 epochs. How did it go?"
      ],
      "metadata": {
        "id": "4kh67J7cNR2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the weights we've saved before in the food vision checkpoint\n",
        "model_0.load_weights('food_vision_checkpoint/')"
      ],
      "metadata": {
        "id": "pyQXUTLnntQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Refreeze every layer except for the last 30\n",
        "for layer in base_model.layers[:-30]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "9aI-6tKrGYOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num , layer in enumerate(model_0.layers[2].layers):\n",
        "  print(num,layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "kwe8vVRFIGln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "4PjEtQX2oEay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = initial_epochs + 10\n",
        "history_fine_tune_model_30 = model_0.fit(train_data_10_percent,\n",
        "                                      epochs = fine_tune_epochs ,\n",
        "                                      steps_per_epoch=len(train_data_10_percent),\n",
        "                                      validation_data = test_data ,\n",
        "                                      validation_steps = len(test_data),\n",
        "                                      initial_epoch =history_10_percent.epoch[-1])"
      ],
      "metadata": {
        "id": "abcWykFboKk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 4. Write a function to visualize an image from any dataset (train or test file) and any class (e.g. \"steak\", \"pizza\"... etc), visualize it and make a prediction on it using a trained model."
      ],
      "metadata": {
        "id": "waKHac3N08aP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUMhBWjWpHAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}